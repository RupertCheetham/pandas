{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of exercises focuses on using Pandas, a powerful library for data manipulation and analysis in Python. You'll learn to create and manipulate DataFrames, work with real-world datasets, handle missing values, and perform various data operations. The exercises cover key Pandas functionalities including data loading, cleaning, transformation, and basic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "NumPy:\n",
      "DataFrame from NumPy array:\n",
      "   color     list number\n",
      "1   Blue   [1, 2]    1.1\n",
      "3    Red   [3, 4]    2.2\n",
      "5   Pink   [5, 6]    3.3\n",
      "7   Grey   [7, 8]    4.4\n",
      "9  Black  [9, 10]    5.5\n",
      "\n",
      "DataFrame from Pandas Series:\n",
      "   color     list  number\n",
      "1   Blue   [1, 2]     1.1\n",
      "3    Red   [3, 4]     2.2\n",
      "5   Pink   [5, 6]     3.3\n",
      "7   Grey   [7, 8]     4.4\n",
      "9  Black  [9, 10]     5.5 \n",
      "\n",
      "1.2\n",
      "First value types:\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "First value types:\n",
      "<class 'str'> <class 'list'> <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "print(1.1)\n",
    "print(\"NumPy:\")\n",
    "# Create a NumPy array\n",
    "data_np = np.array([\n",
    "    [\"Blue\", [1, 2], 1.1],\n",
    "    [\"Red\", [3, 4], 2.2],\n",
    "    [\"Pink\", [5, 6], 3.3],\n",
    "    [\"Grey\", [7, 8], 4.4],\n",
    "    [\"Black\", [9, 10], 5.5]\n",
    "], dtype=object)\n",
    "\n",
    "# Create DataFrame\n",
    "df_np = pd.DataFrame(\n",
    "    data_np,\n",
    "    columns=[\"color\", \"list\", \"number\"],\n",
    "    index=[1, 3, 5, 7, 9]\n",
    "    )\n",
    "\n",
    "print(\"DataFrame from NumPy array:\")\n",
    "print(df_np)\n",
    "\n",
    "# Create Series\n",
    "colors = pd.Series([\"Blue\", \"Red\", \"Pink\", \"Grey\", \"Black\"], index=[1, 3, 5, 7, 9])\n",
    "lists = pd.Series([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]], index=[1, 3, 5, 7, 9])\n",
    "numbers = pd.Series([1.1, 2.2, 3.3, 4.4, 5.5], index=[1, 3, 5, 7, 9])\n",
    "\n",
    "# Create DataFrame\n",
    "df_series = pd.DataFrame({\"color\": colors, \"list\": lists, \"number\": numbers})\n",
    "\n",
    "print(\"\\nDataFrame from Pandas Series:\")\n",
    "print(df_series, \"\\n\")\n",
    "\n",
    "# 1.2\n",
    "print(1.2)\n",
    "print(\"First value types:\")\n",
    "print(type(df_series[\"color\"]))  \n",
    "print(type(df_series[\"list\"]))  \n",
    "print(type(df_series[\"number\"])) \n",
    "\n",
    "print(\"\\nFirst value types:\")\n",
    "df_np[\"number\"] = df_np[\"number\"].astype(np.float64)\n",
    "print(type(df_np.iloc[0, 0]), type(df_np.iloc[0, 1]), type(df_np.iloc[0, 2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Electric power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for opening https://assets.01-edu.org/ai-branch/piscine-ai/household_power_consumption.txt\n",
    "\n",
    "url = \"https://assets.01-edu.org/ai-branch/piscine-ai/household_power_consumption.txt\"\n",
    "# Load the dataset\n",
    "df = pd.read_csv(url, delimiter=\";\", low_memory=False)\n",
    "df[\"Global_active_power\"] = pd.to_numeric(df[\"Global_active_power\"], errors=\"coerce\")\n",
    "df[\"Global_reactive_power\"] = pd.to_numeric(df[\"Global_reactive_power\"], errors=\"coerce\")\n",
    "df[\"Voltage\"] = pd.to_numeric(df[\"Voltage\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1\n",
      "The axis parameter defaults to axis=1 for columns, so there's no need to explicitly specify it.\n"
     ]
    }
   ],
   "source": [
    "# Delete the columns Time, Sub_metering_2 and Sub_metering_3\n",
    "print(2.1)\n",
    "df.drop(columns=[\"Time\", \"Sub_metering_2\", \"Sub_metering_3\"], inplace=True)\n",
    "print(\"The axis parameter defaults to axis=1 for columns, so there's no need to explicitly specify it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2\n",
      "DatetimeIndex(['2006-12-16', '2006-12-16', '2006-12-16', '2006-12-16',\n",
      "               '2006-12-16'],\n",
      "              dtype='datetime64[ns]', name='Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Set Date as index\n",
    "print(\"2.2\")\n",
    "# Convert 'Date' to datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\")\n",
    "# Set 'Date' as the index\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "print(df.head().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n",
      "Global_active_power      float64\n",
      "Global_reactive_power    float64\n",
      "Voltage                  float64\n",
      "Global_intensity         float64\n",
      "Sub_metering_1           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a function that takes as input the DataFrame with the data set and returns a DataFrame with updated types:\n",
    "print(2.3)\n",
    "\n",
    "def update_types(df):\n",
    "    # Convert specific columns to their correct types\n",
    "    df[\"Global_active_power\"] = pd.to_numeric(df[\"Global_active_power\"], errors=\"coerce\")\n",
    "    df[\"Global_reactive_power\"] = pd.to_numeric(df[\"Global_reactive_power\"], errors=\"coerce\")\n",
    "    df[\"Global_intensity\"] = pd.to_numeric(df[\"Global_intensity\"], errors=\"coerce\")\n",
    "    df[\"Sub_metering_1\"] = pd.to_numeric(df[\"Sub_metering_1\"], errors=\"coerce\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = update_types(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Global_active_power  Global_reactive_power       Voltage  \\\n",
      "count         2.049280e+06           2.049280e+06  2.049280e+06   \n",
      "mean          1.091615e+00           1.237145e-01  2.408399e+02   \n",
      "std           1.057294e+00           1.127220e-01  3.239987e+00   \n",
      "min           7.600000e-02           0.000000e+00  2.232000e+02   \n",
      "25%           3.080000e-01           4.800000e-02  2.389900e+02   \n",
      "50%           6.020000e-01           1.000000e-01  2.410100e+02   \n",
      "75%           1.528000e+00           1.940000e-01  2.428900e+02   \n",
      "max           1.112200e+01           1.390000e+00  2.541500e+02   \n",
      "\n",
      "       Global_intensity  Sub_metering_1  \n",
      "count      2.049280e+06    2.049280e+06  \n",
      "mean       4.627759e+00    1.121923e+00  \n",
      "std        4.444396e+00    6.153031e+00  \n",
      "min        2.000000e-01    0.000000e+00  \n",
      "25%        1.400000e+00    0.000000e+00  \n",
      "50%        2.600000e+00    0.000000e+00  \n",
      "75%        6.400000e+00    0.000000e+00  \n",
      "max        4.840000e+01    8.800000e+01  \n"
     ]
    }
   ],
   "source": [
    "# Use describe to have an overview on the data set\n",
    "print(2.4)\n",
    "\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "number of missing values before dropna is: Global_active_power      25979\n",
      "Global_reactive_power    25979\n",
      "Voltage                  25979\n",
      "Global_intensity         25979\n",
      "Sub_metering_1           25979\n",
      "dtype: int64 \n",
      "\n",
      "number of missing values after dropna is: Global_active_power      0\n",
      "Global_reactive_power    0\n",
      "Voltage                  0\n",
      "Global_intensity         0\n",
      "Sub_metering_1           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Delete the rows with missing values\n",
    "print(2.5)\n",
    "print(\"number of missing values before dropna is:\", df.isna().sum(), \"\\n\")\n",
    "df.dropna(inplace=True)\n",
    "print(\"number of missing values after dropna is:\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6\n",
      "Date\n",
      "2006-12-16    0.06\n",
      "2006-12-16    0.06\n",
      "2006-12-16    0.06\n",
      "2006-12-16    0.06\n",
      "2006-12-16    0.06\n",
      "              ... \n",
      "2010-11-26    0.06\n",
      "2010-11-26    0.06\n",
      "2010-11-26    0.06\n",
      "2010-11-26    0.06\n",
      "2010-11-26    0.06\n",
      "Name: Sub_metering_1, Length: 2049280, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Modify Sub_metering_1 by adding 1 to it and multiplying the total by 0.06. If x is a row the output is: (x+1)*0.06\n",
    "print(2.6)\n",
    "df.loc[:,'Sub_metering_1'] = (df['Sub_metering_1'] + 1) * 0.06\n",
    "\n",
    "print(df.loc[:,'Sub_metering_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Date                |   Global_active_power |   Global_reactive_power |   Voltage |   Global_intensity |   Sub_metering_1 |\n",
      "|:--------------------|----------------------:|------------------------:|----------:|-------------------:|-----------------:|\n",
      "| 2008-12-27 00:00:00 |                 0.996 |                   0.066 |    244.81 |                4   |             0.06 |\n",
      "| 2008-12-27 00:00:00 |                 1.076 |                   0.162 |    244.78 |                4.4 |             0.06 |\n",
      "| 2008-12-27 00:00:00 |                 1.064 |                   0.172 |    244.74 |                4.4 |             0.06 |\n",
      "| 2008-12-27 00:00:00 |                 1.07  |                   0.174 |    245.28 |                4.4 |             0.06 |\n",
      "| 2008-12-27 00:00:00 |                 0.804 |                   0.184 |    246.3  |                3.4 |             0.06 |\n",
      "\n",
      "Number of rows in filtered_df is:  449667\n"
     ]
    }
   ],
   "source": [
    "# Select all the rows for which the Date is greater or equal than 2008-12-27 and Voltage is greater or equal than 242\n",
    "print(2.7)\n",
    "# Ensure index is in datetime format\n",
    "df.index = pd.to_datetime(df.index, format=\"%d/%m/%Y\")\n",
    "\n",
    "# Filter rows where Date >= '2008-12-27' and Voltage >= 242\n",
    "filtered_df = df.loc[(df.index >= \"2008-12-27\") & (df[\"Voltage\"] >= 242)]\n",
    "\n",
    "print(filtered_df.head().to_markdown())\n",
    "print(\"\\nNumber of rows in filtered_df is: \", len(filtered_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8\n",
      "Global_active_power        0.254\n",
      "Global_reactive_power      0.000\n",
      "Voltage                  238.100\n",
      "Global_intensity           1.200\n",
      "Sub_metering_1             0.060\n",
      "Name: 2007-02-16 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the 88888th row.\n",
    "print(2.8)\n",
    "\n",
    "print(df.iloc[88887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9\n",
      "2009-02-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# What is the date for which the Global_active_power is maximal ?\n",
    "print(2.9)\n",
    "\n",
    "# Find the date with the maximal value for 'Global_active_power'\n",
    "max_global_active_power_row = df.loc[df[\"Global_active_power\"].idxmax()]\n",
    "\n",
    "# Extract the date corresponding to the maximal global active power\n",
    "max_global_active_power_date = max_global_active_power_row.index\n",
    "print(max_global_active_power_date[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1\n",
      "| Date                |   Global_active_power |   Global_reactive_power |   Voltage |\n",
      "|:--------------------|----------------------:|------------------------:|----------:|\n",
      "| 2008-08-28 00:00:00 |                 0.076 |                       0 |    234.88 |\n",
      "| 2008-08-28 00:00:00 |                 0.076 |                       0 |    235.18 |\n",
      "| 2008-08-28 00:00:00 |                 0.076 |                       0 |    235.4  |\n",
      "| 2008-08-28 00:00:00 |                 0.076 |                       0 |    235.64 |\n",
      "| 2008-08-12 00:00:00 |                 0.076 |                       0 |    236.5  |\n"
     ]
    }
   ],
   "source": [
    "# Sort the first three columns by descending order of Global_active_power and ascending order of Voltage.\n",
    "print(2.10)\n",
    "\n",
    "first_three_columns = df.iloc[:, :3]\n",
    "# Sort the first three columns by descending order of 'Global_active_power' and ascending order of 'Voltage'\n",
    "sorted_df = first_three_columns.sort_values(by=[\"Global_active_power\", \"Voltage\"], ascending=[False, True])\n",
    "\n",
    "print(sorted_df.tail().to_markdown())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11\n",
      "Date\n",
      "2006-12-16    3.053475\n",
      "2006-12-17    2.354486\n",
      "2006-12-18    1.530435\n",
      "2006-12-19    1.157079\n",
      "2006-12-20    1.545658\n",
      "                ...   \n",
      "2010-11-22    1.417733\n",
      "2010-11-23    1.095511\n",
      "2010-11-24    1.247394\n",
      "2010-11-25    0.993864\n",
      "2010-11-26    1.178230\n",
      "Freq: D, Name: Global_active_power, Length: 1442, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the daily average of Global_active_power.\n",
    "print(2.11)\n",
    "# Compute the daily average of 'Global_active_power'\n",
    "daily_avg = df['Global_active_power'].resample('D').mean()\n",
    "\n",
    "# Print the result\n",
    "print(daily_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: E-commerce purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# code for opening Ecommerce_purchases.txt - some of the data contains \\n, which read_csv did not like\n",
    "fixed_lines = []\n",
    "with open(\"Ecommerce_purchases.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    temp_row = []\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) < 14:  # If the row is incomplete, assume it's a split address\n",
    "            temp_row += row  # Merge with the next line\n",
    "        else:\n",
    "            temp_row = row  # Normal row\n",
    "        if len(temp_row) == 14:  # Only add complete rows\n",
    "            fixed_lines.append(temp_row)\n",
    "            temp_row = []\n",
    "            \n",
    "# Save fixed data\n",
    "with open(\"ecommerce_fixed.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(fixed_lines)\n",
    "\n",
    "# Load into pandas\n",
    "ecommerce_df = pd.read_csv(\"ecommerce_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1\n",
      "Number of columns: 14\n",
      "Number of entries: 10000\n"
     ]
    }
   ],
   "source": [
    "# How many rows and columns are there?\n",
    "print(3.1)\n",
    "print(f\"Number of columns: {ecommerce_df.shape[1]}\")\n",
    "print(\"Number of entries:\",len(ecommerce_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2\n",
      "The average Purchase Price is:\n",
      "50.347302\n"
     ]
    }
   ],
   "source": [
    "# What is the average Purchase Price?\n",
    "print(3.2)\n",
    "print(\"The average Purchase Price is:\")\n",
    "print(ecommerce_df['Purchase Price'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3\n",
      "The highest Purchase Price is:\n",
      "99.99\n",
      "The lowest Purchase Price is:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# What were the highest and lowest purchase prices?\n",
    "print(3.3)\n",
    "print(\"The highest Purchase Price is:\")\n",
    "print(ecommerce_df['Purchase Price'].max())\n",
    "print(\"The lowest Purchase Price is:\")\n",
    "print(ecommerce_df['Purchase Price'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4\n",
      "Number of people with English ('en') as their language: 1098\n"
     ]
    }
   ],
   "source": [
    "# How many people have English 'en' as their Language of choice on the website?\n",
    "print(3.4)\n",
    "num_english_speakers = ecommerce_df[ecommerce_df[\"Language\"] == \"en\"].shape[0]\n",
    "print(f\"Number of people with English ('en') as their language: {num_english_speakers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "Number of people who have the job title of Lawyer: 30\n"
     ]
    }
   ],
   "source": [
    "# How many people have the job title of \"Lawyer\" ?\n",
    "print(3.5)\n",
    "num_of_lawyers = ecommerce_df[ecommerce_df[\"Job\"] == \"Lawyer\"].shape[0]\n",
    "print(f\"Number of people who have the job title of Lawyer: {num_of_lawyers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n",
      "AM Purchases: 4932\n",
      "PM Purchases: 5068\n"
     ]
    }
   ],
   "source": [
    "# How many people made the purchase during the AM and how many people made the purchase during PM ?\n",
    "print(3.6)\n",
    "purchase_counts = ecommerce_df[\"AM or PM\"].value_counts()\n",
    "am_count = purchase_counts.get(\"AM\", 0)\n",
    "pm_count = purchase_counts.get(\"PM\", 0)\n",
    "\n",
    "print(f\"AM Purchases: {am_count}\")\n",
    "print(f\"PM Purchases: {pm_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n",
      "Job\n",
      "Interior and spatial designer    31\n",
      "Lawyer                           30\n",
      "Social researcher                28\n",
      "Purchasing manager               27\n",
      "Designer, jewellery              27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# What are the 5 most common Job Titles?\n",
    "print(3.7)\n",
    "job_counts = ecommerce_df[\"Job\"].value_counts()\n",
    "\n",
    "top_5_jobs = job_counts.head(5)\n",
    "print(top_5_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "Purchase Price for Lot '90 WT': 75.1\n"
     ]
    }
   ],
   "source": [
    "# Someone made a purchase that came from Lot: \"90 WT\" , what was the Purchase Price for this transaction?\n",
    "print(3.8)\n",
    "transaction = ecommerce_df[ecommerce_df[\"Lot\"] == \"90 WT\"]\n",
    "\n",
    "# Get the Purchase Price for that transaction\n",
    "purchase_price = transaction[\"Purchase Price\"].iloc[0]\n",
    "print(f\"Purchase Price for Lot '90 WT': {purchase_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9\n",
      "Email for CC number for Lot '4926535242672853': bondellen@williams-garza.com\n"
     ]
    }
   ],
   "source": [
    "# What is the email of the person with the following Credit Card Number: 4926535242672853 ?\n",
    "print(3.9)\n",
    "transaction = ecommerce_df[ecommerce_df[\"Credit Card\"] == 4926535242672853]\n",
    "\n",
    "# Get the Email for that transaction\n",
    "email = transaction[\"Email\"].iloc[0]\n",
    "print(f\"Email for CC number for Lot '4926535242672853': {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1\n",
      "American Express purchases over $95': 39\n"
     ]
    }
   ],
   "source": [
    "# How many people have American Express as their Credit Card Provider and made a purchase above $95 ?\n",
    "print(3.10)\n",
    "transactions_with_purchase_price_greater_than_95 = ecommerce_df[ecommerce_df[\"Purchase Price\"] > 95]\n",
    "\n",
    "# Get the Email for that transaction\n",
    "American_Express_transactions_over_95 = transactions_with_purchase_price_greater_than_95[transactions_with_purchase_price_greater_than_95[\"CC Provider\"] == \"American Express\"]\n",
    "print(f\"American Express purchases over $95': {len(American_Express_transactions_over_95)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11\n",
      "The number of people who have a credit card that expires in 2025 is:\n",
      "1033\n"
     ]
    }
   ],
   "source": [
    "# How many people have a credit card that expires in 2025?\n",
    "print(3.11)\n",
    "number_of_people = ecommerce_df[ecommerce_df['CC Exp Date'].str.endswith('/25')]\n",
    "\n",
    "print(\"The number of people who have a credit card that expires in 2025 is:\")\n",
    "print(number_of_people.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12\n",
      "hotmail.com: 1638\n",
      "yahoo.com: 1616\n",
      "gmail.com: 1605\n",
      "smith.com: 42\n",
      "williams.com: 37\n"
     ]
    }
   ],
   "source": [
    "# What are the top 5 most popular email providers/hosts (e.g. gmail.com, yahoo.com, etc...)\n",
    "print(3.12)\n",
    "\n",
    "Email_Providers = ecommerce_df['Email'].apply(lambda x: x.split('@')[1])\n",
    "\n",
    "top_providers = Email_Providers.value_counts().head(5)\n",
    "\n",
    "for provider, count in top_providers.items():\n",
    "    print(f\"{provider}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Handling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV, assuming it's comma-delimited and ignoring the first column if it's an index\n",
    "df = pd.read_csv(\"iris.csv\", delimiter=\",\")\n",
    "\n",
    "# Drop the 'flower' column as requested\n",
    "df.drop(columns=['flower'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1\n",
      "\n",
      "Line 102, with missing sepal_length value:\n",
      "sepal_length    NaN\n",
      "sepal_width     3.3\n",
      "petal_length    NaN\n",
      "petal_width     2.5\n",
      "Name: 100, dtype: object\n",
      "Line 39, with missing sepal_width value:\n",
      "sepal_length    4.9\n",
      "sepal_width     NaN\n",
      "petal_length    1.5\n",
      "petal_width     0.1\n",
      "Name: 37, dtype: object\n",
      "Line 28, with missing petal_length value:\n",
      "sepal_length    5.0\n",
      "sepal_width     3.4\n",
      "petal_length    NaN\n",
      "petal_width     0.4\n",
      "Name: 26, dtype: object\n",
      "\n",
      "Line 102, added sepal_length value:\n",
      "sepal_length    56.907534\n",
      "sepal_width      3.300000\n",
      "petal_length     0.000000\n",
      "petal_width      2.500000\n",
      "Name: 100, dtype: float64\n",
      "Line 39, added sepal_width value:\n",
      "sepal_length    4.9\n",
      "sepal_width     3.0\n",
      "petal_length    1.5\n",
      "petal_width     0.1\n",
      "Name: 37, dtype: float64\n",
      "Line 28, added petal_length value:\n",
      "sepal_length    5.0\n",
      "sepal_width     3.4\n",
      "petal_length    0.0\n",
      "petal_width     0.4\n",
      "Name: 26, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Then try to fill missing values with different strategies:\n",
    "# sepal_length -> mean\n",
    "# sepal_width -> median\n",
    "# petal_length, petal_width -> 0\n",
    "print(4.1)\n",
    "print(\"\\nLine 102, with missing sepal_length value:\")\n",
    "print(df.loc[100])\n",
    "print(\"Line 39, with missing sepal_width value:\")\n",
    "print(df.loc[37])\n",
    "print(\"Line 28, with missing petal_length value:\")\n",
    "print(df.loc[26])\n",
    "\n",
    "cols_to_convert = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "fill_strategies = {\n",
    "    'sepal_length': df['sepal_length'].mean(),  # Fill with mean\n",
    "    'sepal_width': df['sepal_width'].median(),  # Fill with median\n",
    "    'petal_length': 0,  # Fill with 0\n",
    "    'petal_width': 0     # Fill with 0\n",
    "}\n",
    "\n",
    "# Apply the strategies efficiently\n",
    "df.fillna(value=fill_strategies, inplace=True)\n",
    "\n",
    "print(\"\\nLine 102, added sepal_length value:\")\n",
    "print(df.loc[100])\n",
    "print(\"Line 39, added sepal_width value:\")\n",
    "print(df.loc[37])\n",
    "print(\"Line 28, added petal_length value:\")\n",
    "print(df.loc[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n",
      "Line 28, missing petal_length value:\n",
      "sepal_length    5.0\n",
      "sepal_width     3.4\n",
      "petal_length    NaN\n",
      "petal_width     0.4\n",
      "Name: 26, dtype: object\n",
      "\n",
      "Line 28, added median petal_length value:\n",
      "sepal_length    5.0\n",
      "sepal_width     3.4\n",
      "petal_length    4.5\n",
      "petal_width     0.4\n",
      "Name: 26, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fill the missing values using the median of the associated column using fillna.\n",
    "print(4.2)\n",
    "\n",
    "# get a fresh dataframe since fillna will no longer work - I already filled in the missing data in the previous question\n",
    "# Read the CSV, assuming it's comma-delimited and ignoring the first column if it's an index\n",
    "df2 = pd.read_csv(\"iris.csv\", delimiter=\",\")\n",
    "\n",
    "# Drop the 'flower' column as requested\n",
    "df2.drop(columns=['flower'], inplace=True)\n",
    "\n",
    "print(\"Line 28, missing petal_length value:\")\n",
    "print(df2.loc[26])\n",
    "\n",
    "cols_to_convert = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df2[cols_to_convert] = df2[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "fill_strategies = {\n",
    "    'petal_length': df2['petal_length'].median(),\n",
    "    'petal_width': df2['petal_width'].median()\n",
    "}\n",
    "\n",
    "df2.fillna(value=fill_strategies, inplace=True)\n",
    "\n",
    "print(\"\\nLine 28, added median petal_length value:\")\n",
    "print(df2.loc[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean      56.907534    49.648000     12.423333    11.786000\n",
      "std      564.489133   404.506037    114.078057   130.550042\n",
      "min       -4.400000    -3.600000     -4.800000    -2.500000\n",
      "25%        5.100000     2.800000      1.300000     0.225000\n",
      "50%        5.800000     3.000000      4.000000     1.300000\n",
      "75%        6.500000     3.300000      4.975000     1.800000\n",
      "max     6900.000000  3809.000000   1400.000000  1600.000000\n",
      "\n",
      "Unusual flower:\n",
      "sepal_length      always\n",
      "sepal_width        check\n",
      "petal_length         the\n",
      "petal_width         data\n",
      "flower          !!!!!!!!\n",
      "Name: 122, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Bonus: Why is Filling with 0 or Mean a Bad Idea?\n",
    "\n",
    "#     Filling with 0 can distort relationships\n",
    "#         If 0 isn’t a natural value in the dataset, it can introduce bias.\n",
    "#         This affects statistical calculations, especially with features that don't logically have zero as a valid value.\n",
    "\n",
    "#     Filling with the Mean can reduce variability\n",
    "#         It shrinks the dataset’s natural variation, making the data more uniform than it should be.\n",
    "#         If too many values are missing, the dataset becomes artificially centered, potentially leading to misleading conclusions.\n",
    "\n",
    "# Better alternatives?\n",
    "\n",
    "#     Use the median instead of the mean for skewed data.\n",
    "#     Use interpolation or predictive modeling (e.g., regression or KNN imputation) for more intelligent missing value estimation.\n",
    "\n",
    "print(df.describe())  # Look for extreme values\n",
    "print(\"\\nUnusual flower:\")\n",
    "\n",
    "df3 = pd.read_csv(\"iris.csv\", delimiter=\",\")\n",
    "\n",
    "print(df3.loc[122])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ex00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
